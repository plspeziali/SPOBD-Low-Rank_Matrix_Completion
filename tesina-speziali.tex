\documentclass[12pt,a4paper]{report}
\usepackage[italian]{babel}
%\usepackage[T1]{fontenc} % Riga da commentare se si compila con PDFLaTeX
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{lipsum} % genera testo fittizio
\usepackage[nottoc,numbib]{tocbibind}
\usepackage{titlesec}
\usepackage{cochineal}
\usepackage[cochineal]{newtxmath}
\usepackage[simplified]{pgf-umlcd}
\usepackage{float}
\usepackage{wrapfig,lipsum}
\usepackage{fancyhdr, etoolbox}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{xparse}
\usepackage{url}
\usepackage{setspace}
\usepackage{longtable}
\usepackage{etaremune}
\usepackage{subfig}
\usepackage[edges]{forest}
\definecolor{folderbg}{RGB}{124,166,198}
\definecolor{folderborder}{RGB}{110,144,169}
\newlength\Size
\setlength\Size{4pt}
\tikzset{%
  folder/.pic={%
    \filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.05*\Size,0.2\Size+5pt) rectangle ++(.75*\Size,-0.2\Size-5pt);
    \filldraw [draw=folderborder, top color=folderbg!50, bottom color=folderbg] (-1.15*\Size,-\Size) rectangle (1.15*\Size,\Size);
  },
  file/.pic={%
    \filldraw [draw=folderborder, top color=folderbg!5, bottom color=folderbg!10] (-\Size,.4*\Size+5pt) coordinate (a) |- (\Size,-1.2*\Size) coordinate (b) -- ++(0,1.6*\Size) coordinate (c) -- ++(-5pt,5pt) coordinate (d) -- cycle (d) |- (c) ;
  },
}
\forestset{%
  declare autowrapped toks={pic me}{},
  pic dir tree/.style={%
    for tree={%
      folder,
      font=\ttfamily,
      grow'=0,
    },
    before typesetting nodes={%
      for tree={%
        edge label+/.option={pic me},
      },
    },
  },
  pic me set/.code n args=2{%
    \forestset{%
      #1/.style={%
        inner xsep=2\Size,
        pic me={pic {#2}},
      }
    }
  },
  pic me set={directory}{folder},
  pic me set={file}{file},
}
\include{json-lang}
\usepackage[style=numeric-comp,useprefix,hyperref,backend=bibtex]{biblatex}


\NewDocumentCommand{\codeword}{v}{%
    \texttt{\textcolor{blue}{#1}}%
}

\lstset{language=C,keywordstyle={\bfseries \color{blue}}}

%\usetikzlibrary{calc}
\pagestyle{fancy}

\fancyhead{}
\fancyhead[OL]{\ifnumodd{\value{page}}{\slshape \leftmark}{\slshape SEZIONE \rightmark}}
\fancypagestyle{mystyle}{
    \fancyhead[OL]{\slshape \leftmark}
}
\fancyfoot[C]{\thepage}

\fontfamily{bch}\selectfont

% Taken from Lena Herrmann at
% http://lenaherrmann.net/2010/05/20/javascript-syntax-highlighting-in-the-latex-listings-package

\usepackage{color} %use color
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

%Customize a bit the look
\lstset{ %
backgroundcolor=\color{white}, % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
basicstyle=\footnotesize, % the size of the fonts that are used for the code
breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace
breaklines=true, % sets automatic line breaking
captionpos=b, % sets the caption-position to bottom
commentstyle=\color{mygreen}, % comment style
deletekeywords={...}, % if you want to delete keywords from the given language
escapeinside={<@}{@>}, % if you want to add LaTeX within your code
extendedchars=true, % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
frame=single, % adds a frame around the code
keepspaces=true, % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
keywordstyle=\color{blue}, % keyword style
% language=Octave, % the language of the code
morekeywords={*,...}, % if you want to add more keywords to the set
numbers=left, % where to put the line-numbers; possible values are (none, left, right)
numbersep=5pt, % how far the line-numbers are from the code
numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
rulecolor=\color{black}, % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
showspaces=false, % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
showstringspaces=false, % underline spaces within strings only
showtabs=false, % show tabs within strings adding particular underscores
stepnumber=1, % the step between two line-numbers. If it's 1, each line will be numbered
stringstyle=\color{mymauve}, % string literal style
tabsize=1, % sets default tabsize to 2 spaces
title=\lstname, % show the filename of files included with \lstinputlisting; also try caption instead of title
}
%END of listing package%

\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

%define Javascript language
\lstdefinelanguage{JavaScript}{
keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, while, do, else, case, break, for, of, const, async, await},
keywordstyle=\color{blue}\bfseries,
ndkeywords={class, export, boolean, throw, implements, import},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{purple}\ttfamily,
stringstyle=\color{red}\ttfamily,
morestring=[b]',
morestring=[b]"
}

\lstset{
language=JavaScript,
extendedchars=true,
basicstyle=\footnotesize\ttfamily,
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\footnotesize,
numbersep=9pt,
tabsize=1,
breaklines=true,
showtabs=false,
captionpos=b
}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\usepackage{listings}
\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  tabsize=1,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{$$},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\normtwo}[1]{\left\lVert#1\right\rVert _2^2}
\newcommand{\nukenorm}[1]{\left\lVert#1\right\rVert _*}
\newcommand{\frobnorm}[1]{\left\lVert#1\right\rVert _F}
\newcommand{\R}{\mathbb{R}}
\newcommand{\ux}{\underline{x}}
\newcommand{\uy}{\underline{y}}
\newcommand{\ug}{\underline{g}}
\newcommand{\ue}{\underline{e}}
\newcommand{\uk}{\underline{k}}
\newcommand{\uw}{\underline{w}}
\newcommand{\uv}{\underline{v}}
\newcommand{\ub}{\underline{b}}
\newcommand{\uc}{\underline{c}}
\newcommand{\uone}{\underline{1}}
\newcommand{\ut}{\underline{\theta}}
\newcommand{\est}{\underline{\hat{\theta}}}

\newcommand{\mF}{\mathcal{F}}
\newcommand{\mS}{\mathcal{S}}


\titleformat{\chapter}[display]{\Huge\bfseries}{}{0pt}{\thechapter.\ }

\graphicspath{{figures/}}
%
%\addtolength{\topmargin}{-.875in} % reduce the default top margin
%\addtolength{\topmargin}{-2cm} % reduce the default top margin
%

\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                %
%     Begin Docuemnt [start]     %
%                                %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Title Page [start]     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Declare new goemetry for the title page only.
{\Large \noindent Paolo Speziali} \newline

\vspace{1cm}

{\begin{flushleft}

  {\normalsize \noindent Tesina di}
  \vspace{0.2cm}
  
  {\Large \noindent Signal Processing and Optimization for Big Data}

  \vspace{0.2cm}
  
  {\large \noindent del Prof.~Paolo Banelli}

  \vspace{2cm}

  \fontsize{21.8}{26.16} \selectfont \bfseries \noindent 
  Low-Rank Matrix Completion \\
  con implementazione e \\ 
  verifica sperimentale \\
  \end{flushleft}}
  
  \vspace{4cm}


\noindent Perugia, Anno Accademico 2022/2023

\noindent Università degli Studi di Perugia \\
Corso di laurea magistrale in Ingegneria Informatica e Robotica \\
Curriculum Data Science \\
Dipartimento di Ingegneria

\vspace{0.7cm}

\noindent \includegraphics[width=0.5\textwidth]{Figures/logounipg2021}
% Ends the declared geometry for the titlepage
\restoregeometry
\end{titlepage}
\normalfont
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Title Page [end]     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \thispagestyle{empty} \ \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%
%     Indice [start]     %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\onehalfspacing
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%
%     Indice [end]     %
%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introduzione}

Lo scopo di questa tesina è l'implementazione in ambiente MATLAB di tre algoritmi
atti a risolvere il problema dello stimare i valori mancanti di una matrice di cui
abbiamo a disoposizione solo un sottoinsieme limtato di entry.

{\let\clearpage\relax\chapter{Concetti teorici}}

\section{Formulazione del problema}

Sia $M\in\mathbb{R}^{n_1\times n_2}$ con rango $r$, e sia data la sua scomposizione ai valori
singolari (SVD):
$$M=U\Sigma V^T \quad\text{con}\quad U\in\mathbb{R}^{n_1\times r},
\;\Sigma\in\mathbb{R}^{r\times r},\;V\in\mathbb{R}^{n_2\times r}$$
dove $U$ e $V$ sono composte da colonne ortonormali, e $\Sigma$ è una matrice
diagonale con i valori singolari ordinati in modo non crescente
($\sigma_1\geq\sigma_2\geq\ldots\geq\sigma_r>0$).

I \textbf{gradi di libertà} di $M$ sono $(n_1 + n_2 - r)r$, che è il numero totale di parametri
necessari per specificare univocamente la matrice $M$.

\newpage

Supponiamo di avere delle osservazioni parziali di $M$ su un insieme di indici
$$\Omega \subset \{1,2,\ldots,n_1\}\times\{1,2,\ldots,n_2\}$$
e definiamo l'\textbf{operatore di osservazione}
$\mathcal{P}_{\Omega}:\mathbb{R}^{n_1\times n_2}\to\mathbb{R}^{n_1\times n_2}$ come segue:
$$\left[\mathcal{P}_{\Omega}(M)\right] _{ij}=\left\{\begin{matrix}M_{ij}, & \text{se}\; (i,j)\in X \\ 0, & \text{altrimenti}\end{matrix}\right.$$
Il nostro obiettivo è recuperare $M$ da $\mathcal{P}_{\Omega}(M)$
quando il numero di osservazioni\\ $m = |\Omega| \ll n_1 n_2$, ovvero quando
è molto più piccolo del numero di elementi in $M$, e sotto l'assunzione che $M$
sia a basso rango, ovvero $r\ll\min(n_1,n_2)$.
Per semplicità notazionale, poniamo $n=\max(n_1,n_2)$.

\section{Soluzione del problema}

Quali tipi di matrici a basso rango possiamo completare?
Consideriamo le matrici $M_1$ e $M_2$ di rango $1$ e di dimensione $4 \times 4$:

$$M_1 = \begin{bmatrix}
  1 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0
\end{bmatrix}
\qquad
M_2 = \begin{bmatrix}
  1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1 \\ 1 & 1 & 1 & 1
\end{bmatrix}$$

La matrice $M_1$ è più difficile da completare
poiché la maggior parte delle sue voci sono nulle
e quindi abbiamo bisogno di raccogliere più misure per assicurarsi
che abbastanza ``massa'' venga dalle sue voci non nulle.
Al contrario, la massa di $M_2$ è distribuita più uniformemente su tutte le voci,
rendendolo più facile da propagare da una voce all'altra.

In altre parole, una matrice a basso rango è più facile da completare se la sua energia
si distribuisce uniformemente su diverse coordinate.
Questa proprietà è catturata dalla \textbf{coerenza}, che misura l'allineamento
tra lo spazio delle colonne/righe della matrice a basso rango con i vettori della base standard.

Per una matrice $U\in\mathbb{R}^{n_1\times r}$ con colonne ortonormali,
$P_U$ rappresenta la proiezione ortogonale sullo spazio delle colonne di $U$.
La \textbf{coerenza} di $U$ è definita come segue:
$$ \mu(U) = \frac{n_1}{r}\, \underset{1 \leq i \leq n_1}{max}\, \normtwo{P_U\, \underline{e}_i}
= \frac{n_1}{r}\, \underset{1 \leq i \leq n_1}{max}\, \normtwo{U^T\, \underline{e}_i}$$
dove $\underline{e}_i$ è l'$i$-esimo vettore della base canonica.

Per una matrice a basso rango $M$ il cui SVD è data da $M=U\Sigma V^T$,
la coerenza di $M$ è definita come:

$$ \mu = max\{\mu(U), \mu(V)\} $$

Si noti che la coerenza $\mu$ è determinata dai vettori singolari di $M$ ed
è indipendente dai suoi valori singolari.

Poiché $1\leq \mu(U) \leq \frac{n_1}{r}$
e $1\leq \mu(V) \leq \frac{n_2}{r}$, abbiamo $1\leq \mu \leq \frac{n}{r}$.
Nell'esempio precedente, la coerenza di $M_1$ coincide con il limite superiore
$\frac{n}{r}$, mentre quella di $M_2$ coincide con il limite inferiore $1$.
Più $\mu$ è piccolo, più è facile completare la matrice.

Possiamo incontrare alcune matrici la cui ricostruzione non è possibile,
un esempio sarebbe una matrice con tutti i valori eccetto quelli di una colonna completamente
mancante, essa non potrà essere recuperata in quanto potrebbe giacere ovunque nello
spazio delle colonne della matrice.
Ci servono quindi almeno $r$ osservazioni per colonna/riga.

Per evitare di incorrere in questi casi sfavorevoli, supponiamo di star utilizzando
un pattern di osservazione causale che segua un modello di distribuzione di probabilità
noto come \textbf{Bernoulli}, per cui ogni valore viene osservato indipendentemente
e con probabilità uguale a $p := \frac{m}{n_1\cdot n_2}$.

Non è possibile recuperare una matrice a basso rango con un numero di osservazioni
ad uno dell'ordine di $O(\mu n r \log n)$ utilizzando un qualsiasi algoritmo,
questo è noto come l'\textbf{information-theoretic lower bound}.
Rispetto ai gradi di libertà, che sono dell'ordine di $nr$,
paghiamo un prezzo in complessità di campionamento di un fattore $\mu \log n$,
mettendo ancora una volta in evidenza il ruolo della coerenza nel completamento di matrici a basso rango.

\newpage

\subsection{Completamento di matrici tramite ottimizzazione convessa}

Cercando di sfruttare la struttura a basso rango della soluzione, un'euristica naturale
è trovare la matrice con rango minore che permette tali osservazioni:
$$ \underset{\Phi \in \mathbb{R}^{n_1 \times n_2}}{min}\;\; rank(\Phi) $$
$$ s.t. \;\;  \mathcal{P}_{\Omega}(\Phi) = \mathcal{P}_{\Omega}(M) $$ 
Tuttavia, essendo la minimizzazione del rango un problema NP-arduo,
tale formulazione non è intrattabile, possiamo tuttavia
pensare a un possibile rilassamento di questa euristica.

Notando che il rango di $\Phi$ è uguale al numero dei suoi valori singolari non nulli,
sostituiamo $rank(\Phi)$ con la somma dei suoi valori singolari, indicata come \textbf{nuclear norm}:
$$ \nukenorm{\Phi} \triangleq \sum_{i=1}^n \sigma_i(\Phi) $$
Quindi, invece di risolvere direttamente il problema visto precedentemente,
risolviamo la minimizzazione della nuclear norm, che cerca una matrice con la nuclear norm
minima che soddisfa tutte le misurazioni:
$$ \underset{\Phi \in \mathbb{R}^{n_1 \times n_2}}{min}\;\; \nukenorm{\Phi} $$
$$ s.t. \;\;  \mathcal{P}_{\Omega}(\Phi) = \mathcal{P}_{\Omega}(M) $$ 
Si ottiene così un programma convesso che può
essere risolto in modo efficiente in tempo polinomiale.
Inoltre, non richiede la conoscenza
del rango a priori.

La minimizzazione della nuclear norm può recuperare esattamente
una matrice di basso rango non appena il numero di misurazioni è leggermente più grande
dell'information-theoretic lower bound di un fattore logaritmico.
Supponiamo che ogni valore della matrice $M$ venga osservato indipendentemente
con una probabilità $p \in (0,1)$. Se:
$$ p \leq C \; \frac{\mu r \log^2 n}{n} $$
per una qualche $C>0$ abbastanza grande, allora con grande probabilità
l'algoritmo recupera esattamente 
la matrice $M$ come soluzione ottima.

\subsection{Completamento di matrici tramite ottimizzazione non convessa}

L'algoritmo appena visto può essere particolarmente costoso in termini di tempo e memoria
per problemi su larga scala a causa del dover ottimizzare e memorizzare la variabile $\Phi$.
Pertanto, è necessario considerare approcci alternativi che scalino in modo più favorevole con $n$.
Ciò porta al secondo algoritmo basato su gradient descent utilizzando un'inizializzazione adeguata.

Se il rango della matrice $M$ è noto, è naturale incorporare questa conoscenza 
e considerare un problema least-square vincolato al rango:
$$ \underset{\Phi \in \mathbb{R}^{n_1 \times n_2}}{min}\;\; \frobnorm{\mathcal{P}_{\Omega}(\Phi - M)}^2 $$
$$ s.t. \;\;  rank(\Phi) \leq r $$ 
dove $\frobnorm{\cdot}$ è la \textbf{Frobenius norm} di una matrice.
Utilizzando la fattorizzazione a basso rango $\Phi = XY^T$ dove $X \in \mathbb{R}^{n_1 \times r}$
e $Y \in \mathbb{R}^{n_2 \times r}$, riscriviamo il problema qui sopra come 
un problema d'ottimizzazione non vincolato e non convesso:
$$ \underset{X,Y}{min}\;\; \mathit{f}(X,Y) := \frobnorm{\mathcal{P}_{\Omega}(XY^T - M)}^2 $$
Le complessità a livello di memoria di $X$ e $Y$ sono lineari in $n$
anziché quadratiche, d'altro canto 

\chapter{Implementazione degli algoritmi}



\chapter{Verifica sperimentale}


\hyphenpenalty=0

\cleardoublepage\phantomsection % to fix wrong hyperref to \part{Epilogue}

\end{document}
